{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71427c2a-aecc-469a-9622-f7769c64c709",
   "metadata": {},
   "source": [
    "# Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c6df314-8aac-4842-8f5d-0a106f5f092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tf-keras\n",
    "!pip intsall torch\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install evaluate\n",
    "!pip install nltk\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e941ac5-0da1-4230-bf07-a4eca2019a43",
   "metadata": {},
   "source": [
    "# QA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7bf58505-06a6-4dee-80c7-9a850e2d07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "316fa82f-fefb-4e8c-ad70-f85dd1b6b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_content = \"\"\"Braille is a tactile writing system used by people who are visually impaired or blind. \n",
    "It was developed by Louis Braille in 1824, who himself was blind. Braille consists of patterns of raised dots arranged in cells, \n",
    "where each cell can have up to six dots. The arrangement of these dots represents different letters, numbers, punctuation marks, \n",
    "or even entire words, depending on the language and application.\n",
    "The Braille system is versatile, enabling the blind to read and write not only text but also mathematical expressions \n",
    "(using the Nemeth Braille Code), music notation, and computer symbols. It can be read by touch, with the fingertips feeling the dot patterns. \n",
    "In modern applications, Braille is produced using specialized Braille printers (embossers) or manually with slates and styluses.\n",
    "Advancements in technology have expanded Braille's accessibility through digital devices such as refreshable Braille displays, \n",
    "which dynamically change the dot patterns to represent screen content, helping users interact with computers, smartphones, \n",
    "and other digital systems. While voice recognition and audio interfaces offer alternatives, Braille remains essential for literacy, \n",
    "allowing users to understand written language structure and spelling independently.\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\",\n",
    "                      model=\"deepset/minilm-uncased-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80b394bf-c0cd-48af-928e-3986533637f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6161749958992004, 'start': 174, 'end': 215, 'answer': 'patterns of raised dots arranged in cells'}\n"
     ]
    }
   ],
   "source": [
    "question = \"What is braile consist of?\"\n",
    "answer = qa_pipeline(question = question, context=input_content)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5fb4e25-6bf6-4214-8fd8-b56a94ee9c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another Question\n",
      "\n",
      "Question:  How Braile is produced?\n",
      "Answer:  using specialized Braille printers\n"
     ]
    }
   ],
   "source": [
    "print(\"Another Question\")\n",
    "\n",
    "question = \"How Braile is produced?\"\n",
    "print(\"\\nQuestion: \", question)\n",
    "print('Answer: ', qa_pipeline(question = question, context=input_content)['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747d80a-900b-4074-8f66-237d4a83fc67",
   "metadata": {},
   "source": [
    "## Evaluating QA pipeline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c627414-0092-42ec-9d6b-30654db74378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 for answer 'New Delhi': 100.0\n",
      "F1 for answer 'Mumbai': 0.0\n",
      "F1 for answer 'Bangalore': 0.0\n",
      "Cumulative Results: {'exact': 33.333333333333336, 'f1': 33.333333333333336, 'total': 3, 'HasAns_exact': 33.333333333333336, 'HasAns_f1': 33.333333333333336, 'HasAns_total': 3, 'best_exact': 33.333333333333336, 'best_exact_thresh': 0.0, 'best_f1': 33.333333333333336, 'best_f1_thresh': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "# Load the SQuAD v2 metric\n",
    "squad_metric = load(\"squad_v2\")\n",
    "\n",
    "# Define the correct answer and the list of predicted answers\n",
    "correct_answer = \"New Delhi\"\n",
    "predicted_answers = [\"New Delhi\", \"Mumbai\", \"Bangalore\"]\n",
    "\n",
    "# Initialize lists to store cumulative predictions and references\n",
    "cum_predictions = []\n",
    "cum_references = []\n",
    "\n",
    "# Iterate through the predicted answers and evaluate each one\n",
    "for index, predicted_answer in enumerate(predicted_answers):\n",
    "    predictions = [\n",
    "        {\"prediction_text\": predicted_answer, \"id\": str(index), \"no_answer_probability\": 0.0}\n",
    "    ]\n",
    "    \n",
    "    references = [\n",
    "        {\"answers\": {'answer_start': [1], 'text': [correct_answer]}, \"id\": str(index)}\n",
    "    ]\n",
    "    \n",
    "    # Append to cumulative lists\n",
    "    cum_predictions.append(predictions[0])\n",
    "    cum_references.append(references[0])\n",
    "    \n",
    "    # Compute and print the F1 score for each answer\n",
    "    results = squad_metric.compute(predictions=predictions, references=references)\n",
    "    print(f\"F1 for answer '{predicted_answer}': {results['f1']}\")\n",
    "\n",
    "# Compute and print cumulative results\n",
    "cum_result = squad_metric.compute(predictions=cum_predictions, references=cum_references)\n",
    "print(f\"Cumulative Results: {cum_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb1e7b-2527-4e6c-bc78-28fec5ab248b",
   "metadata": {},
   "source": [
    "# Summarization with pipeplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc491bc0-0c10-4d6d-82d8-661b50838509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6ab4f78-9b77-40ef-834e-15fb4c7ca031",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_content = \"\"\"Braille is a tactile writing system used by people who are visually impaired or blind. \n",
    "It was developed by Louis Braille in 1824, who himself was blind. Braille consists of patterns of raised dots arranged in cells, \n",
    "where each cell can have up to six dots. The arrangement of these dots represents different letters, numbers, punctuation marks, \n",
    "or even entire words, depending on the language and application.\n",
    "The Braille system is versatile, enabling the blind to read and write not only text but also mathematical expressions \n",
    "(using the Nemeth Braille Code), music notation, and computer symbols. It can be read by touch, with the fingertips feeling the dot patterns. \n",
    "In modern applications, Braille is produced using specialized Braille printers (embossers) or manually with slates and styluses.\n",
    "Advancements in technology have expanded Braille's accessibility through digital devices such as refreshable Braille displays, \n",
    "which dynamically change the dot patterns to represent screen content, helping users interact with computers, smartphones, \n",
    "and other digital systems. While voice recognition and audio interfaces offer alternatives, Braille remains essential for literacy, \n",
    "allowing users to understand written language structure and spelling independently.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cb4dc92-e43e-4005-8ce4-917ffcd72467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Braille is a tactile writing system used by people who are visually impaired or blind . It was developed by Louis Braille in 1824, who himself was blind . Braille consists of patterns of raised dots arranged in cells .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "extractive_summarizer = pipeline(\"summarization\",\n",
    "                                min_length=10,\n",
    "                                max_length=100)\n",
    "\n",
    "extractive_summary = extractive_summarizer(input_content)\n",
    "\n",
    "print(extractive_summary[0].get(\"summary_text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27610b07-4f9b-4f21-a217-7a5792e16ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint used: BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"checkpoint used: {extractive_summarizer.model.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e33233-3bab-49ff-ab70-a262542e4fd0",
   "metadata": {},
   "source": [
    "## Evaluating with rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57653ab7-53f1-4a51-aa81-27f20b8dce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_evaluator = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77a2535a-5e7d-4e45-a573-347913dfc43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for exact match:  {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#evaluate exact match strings\n",
    "reference_text = [\"Coding should not stop\"]\n",
    "predict_text = [\"Coding should not stop\"]\n",
    "\n",
    "eval_results = rouge_evaluator.compute(predictions = predict_text, references= reference_text)\n",
    "print(\"Results for exact match: \", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad3cdbf0-5a79-4860-8fe9-1ae636d0c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for no-match:  {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#evaluate no-match strings\n",
    "reference_text = [\"Coding should not stop\"]\n",
    "predict_text = [\"This is something else\"]\n",
    "\n",
    "eval_results = rouge_evaluator.compute(predictions = predict_text, references= reference_text)\n",
    "print(\"Results for no-match: \", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fbbb1ba-c57a-4b91-853a-c2f74ca35ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for summary generated:  {'rouge1': 0.33333333333333337, 'rouge2': 0.32727272727272727, 'rougeL': 0.33333333333333337, 'rougeLsum': 0.33333333333333337}\n"
     ]
    }
   ],
   "source": [
    "# evaluate summary\n",
    "\n",
    "eval_results =rouge_evaluator.compute(\n",
    "    predictions = [extractive_summary[0].get(\"summary_text\")],\n",
    "    references = [input_content]\n",
    ")\n",
    "\n",
    "print(\"Results for summary generated: \", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a168a94-0f4c-4635-8a94-97340d9246ef",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f9936c8-a534-4de4-a00e-7ce4882bede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# to avoid warning messages\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9080ae05-efec-4548-be6b-4f4c91f0a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\",\n",
    "                         model=\"gpt2\")\n",
    "\n",
    "transformers.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab56b503-020c-4dab-a297-354bd4f03dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence No: 1 \n",
      " Natural language processing is a growing domain in machine learning. A large percentage of machine-created content is written in human-friendly, non-technical languages. For example, the following example shows the development of three artificial intelligences: one that can understand the English language but not language that is written on \n",
      "---------\n",
      "Sequence No: 2 \n",
      " Natural language processing is a growing domain in machine learning and there are numerous applications, from the classification of text in books to the ability as an information-processing application for the computer.\n",
      "\n",
      "In this talk I will discuss the core properties of natural language processing and then try to create software for applying it \n",
      "---------\n",
      "Sequence No: 3 \n",
      " Natural language processing is a growing domain in machine learning. This means that learning based on the structure of speech and speech processing have tremendous potential to change the way we think about the world. It just has to be fast and cheap, which is where the company will be investing in the next generation of AI \n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "input_text =\"Natural language processing is a growing domain in machine learning\"\n",
    "\n",
    "synthetic_text = text_generator(input_text,\n",
    "                               num_return_sequences = 3,\n",
    "                               max_new_tokens = 50)\n",
    "\n",
    "for index, text in enumerate(synthetic_text):\n",
    "    print(f\"Sequence No: {index+1} \\n {text.get(\"generated_text\")} \\n---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bc9a7f02-3af9-4010-ac82-885ad49df610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb720ccb-43e8-4d74-b76f-488ef2e7c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "925da52d-0a6b-4da1-aae0-5767bdb7af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "conversational_pipeline = pipeline(\"text2text-generation\",model=\"facebook/blenderbot_small-90M\")\n",
    "\n",
    "# print(conversational_pipeline.model.config)\n",
    "\n",
    "transformers.set_seed(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d3144fc-46f6-47e7-a535-373f91c2e929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Conversation object at 0x16cb3f770>\n",
      "\n",
      "First Exchange: \n",
      "---------------\n",
      "User Input:  Do you have any hobbies?\n",
      "Bot Output:  yes , i love going to the beach . what about you ? do you have any hobbies ?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conversation' object has no attribute 'add_user_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser Input: \u001b[39m\u001b[38;5;124m\"\u001b[39m, bot_conversation\u001b[38;5;241m.\u001b[39mpast_user_inputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot Output: \u001b[39m\u001b[38;5;124m\"\u001b[39m, bot_conversation\u001b[38;5;241m.\u001b[39mgenerated_responses[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m \u001b[43mbot_conversation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_user_input\u001b[49m(second_input)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSecond Exchange: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m bot_conversation\u001b[38;5;241m.\u001b[39mgenerated_responses\u001b[38;5;241m.\u001b[39mappend(conversational_pipeline(second_input)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Conversation' object has no attribute 'add_user_input'"
     ]
    }
   ],
   "source": [
    "# sample inputs\n",
    "\n",
    "first_input = \"Do you have any hobbies?\"\n",
    "second_input = \"I like to watch movies\"\n",
    "third_input = \"action movies\"\n",
    "\n",
    "#create a context\n",
    "bot_conversation = Conversation(first_input)\n",
    "print(bot_conversation)\n",
    "\n",
    "print(\"\\nFirst Exchange: \\n---------------\")\n",
    "bot_conversation.generated_responses.append(conversational_pipeline(first_input)[0]['generated_text'])\n",
    "print(\"User Input: \", bot_conversation.past_user_inputs[0])\n",
    "print(\"Bot Output: \", bot_conversation.generated_responses[0])\n",
    "\n",
    "bot_conversation.add_user_input(second_input)\n",
    "\n",
    "print(\"\\nSecond Exchange: \\n---------------\")\n",
    "bot_conversation.generated_responses.append(conversational_pipeline(second_input)[0]['generated_text'])\n",
    "conversational_pipeline(second_input)\n",
    "print(\"User Input: \", bot_conversation.past_user_inputs[1])\n",
    "print(\"User Input: \", bot_conversation.generated_responses[1])\n",
    "\n",
    "bot_conversation = Conversation(third_input)\n",
    "\n",
    "print(\"\\nThird Exchange: \\n---------------\")\n",
    "\n",
    "conversational_pipeline(bot_conversation)\n",
    "print(\"User Input: \", bot_conversation.past_user_inputs[2])\n",
    "print(\"User Input: \", bot_conversation.generated_responses[2])\n",
    "\n",
    "print(\"\\nAccessing All \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0f270-597e-4207-9b4f-3887a3eaf22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f80ce-d717-4a14-9cac-566bf7714dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58de90-6bba-419c-82de-ade5cb1d5ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2041688-fd35-41d5-80b8-0f4e04404813",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "af141986-318f-4357-9313-c23199a2aa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'verse_text', 'label'],\n",
      "        num_rows: 892\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'verse_text', 'label'],\n",
      "        num_rows: 105\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'verse_text', 'label'],\n",
      "        num_rows: 104\n",
      "    })\n",
      "})\n",
      "{'id': [15, 16, 17, 18, 19], 'verse_text': [\"that we must change for heav'n, this mournful gloom\", 'lo now, o daughter of kings, let us rise in the face of the day,', 'for penance, by a saintly styrian monk', 'upon a mountain crag, young angelo--', \"down in lovah's lane.\"], 'label': [0, 1, 2, 2, 2]}\n",
      "\n",
      "Sentiment lables used ['negative', 'positive', 'no_impact', 'mixed']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = 'poem_sentiment'\n",
    "\n",
    "poem_sentiments = load_dataset(dataset_name)\n",
    "\n",
    "print(poem_sentiments)\n",
    "print(poem_sentiments['test'][15:20])\n",
    "\n",
    "print(\"\\nSentiment lables used\", poem_sentiments['train'].features.get('label').names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83070c-01f5-48e6-95a1-ec1e8607c572",
   "metadata": {},
   "source": [
    "### Encoding Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "487b4c64-f298-4796-8690-eaaa97ef597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [0, 1, 2, 3, 4], 'verse_text': ['with pale blue berries. in these peaceful shades--', 'it flows so long as falls the rain,', 'and that is why, the lonesome day,', 'when i peruse the conquered fame of heroes, and the victories of mighty generals, i do not envy the generals,', 'of inward strife for truth and liberty.'], 'label': [1, 2, 0, 3, 3], 'input_ids': [[101, 2007, 5122, 2630, 22681, 1012, 1999, 2122, 9379, 13178, 1011, 1011, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2009, 6223, 2061, 2146, 2004, 4212, 1996, 4542, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 2008, 2003, 2339, 1010, 1996, 10459, 14045, 2154, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1045, 7304, 3366, 1996, 11438, 4476, 1997, 7348, 1010, 1998, 1996, 9248, 1997, 10478, 11593, 1010, 1045, 2079, 2025, 21103, 1996, 11593, 1010, 102, 0, 0], [101, 1997, 20546, 27865, 2005, 3606, 1998, 7044, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# Encoding Text\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "db_tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return db_tokenizer(batch['verse_text'],\n",
    "                       padding=True,\n",
    "                       truncation=True)\n",
    "    \n",
    "enc_poem_sentiment = poem_sentiments.map(tokenize,\n",
    "                                       batched=True,\n",
    "                                       batch_size=None)\n",
    "\n",
    "print(enc_poem_sentiment['train'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "499a8260-e028-4b7d-826f-4a2385fd7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  it flows so long as falls the rain,\n",
      "Input Map:  [101, 2009, 6223, 2061, 2146, 2004, 4212, 1996, 4542, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Total Tokens:  28\n",
      "Non Zero Tokens:  11\n"
     ]
    }
   ],
   "source": [
    "# Explore Input Ids and Attention mask\n",
    "\n",
    "print(\"Text: \",\n",
    "     enc_poem_sentiment['train'][1].get('verse_text'))\n",
    "\n",
    "print(\"Input Map: \",\n",
    "     enc_poem_sentiment['train'][1].get('input_ids'))\n",
    "\n",
    "print(\"Attention Mask: \",\n",
    "     enc_poem_sentiment['train'][1].get('attention_mask'))\n",
    "\n",
    "print(\"\\nTotal Tokens: \",\n",
    "     len(enc_poem_sentiment['train'][1].get('input_ids')))\n",
    "\n",
    "print(\"Non Zero Tokens: \",\n",
    "     len(list(\n",
    "         filter(\n",
    "             lambda x: x!=0, \n",
    "             enc_poem_sentiment['train'][1].get('input_ids')\n",
    "         )\n",
    "     )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94314a4-346b-42e6-a867-f97b5d5dc4fc",
   "metadata": {},
   "source": [
    "### Separating Train & validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52635c46-e79b-4a50-93f9-2565c666ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:  ['id', 'verse_text', 'label', 'input_ids', 'attention_mask']\n",
      "\n",
      "Features:  {'id': Value(dtype='int32', id=None), 'verse_text': Value(dtype='string', id=None), 'label': ClassLabel(names=['negative', 'positive', 'no_impact', 'mixed'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "# Separate training and validation sets\n",
    "\n",
    "training_dataset = enc_poem_sentiment['train']\n",
    "validation_dataset = enc_poem_sentiment['validation']\n",
    "\n",
    "print(\"\\nColumn Names: \", training_dataset.column_names)\n",
    "print(\"\\nFeatures: \", training_dataset.features)\n",
    "\n",
    "labels = training_dataset.features.get(\"label\")\n",
    "num_labels = len(labels.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8880e-c948-44a3-944e-ec65abfeedbd",
   "metadata": {},
   "source": [
    "### Creating model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "74721939-0e96-4f98-b1f7-72a688f4f032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 30522,\n",
       " 'max_position_embeddings': 512,\n",
       " 'sinusoidal_pos_embds': False,\n",
       " 'n_layers': 6,\n",
       " 'n_heads': 12,\n",
       " 'dim': 768,\n",
       " 'hidden_dim': 3072,\n",
       " 'dropout': 0.1,\n",
       " 'attention_dropout': 0.1,\n",
       " 'activation': 'gelu',\n",
       " 'initializer_range': 0.02,\n",
       " 'qa_dropout': 0.1,\n",
       " 'seq_classif_dropout': 0.2,\n",
       " 'return_dict': True,\n",
       " 'output_hidden_states': False,\n",
       " 'output_attentions': False,\n",
       " 'torchscript': False,\n",
       " 'torch_dtype': None,\n",
       " 'use_bfloat16': False,\n",
       " 'tf_legacy_loss': False,\n",
       " 'pruned_heads': {},\n",
       " 'tie_word_embeddings': True,\n",
       " 'chunk_size_feed_forward': 0,\n",
       " 'is_encoder_decoder': False,\n",
       " 'is_decoder': False,\n",
       " 'cross_attention_hidden_size': None,\n",
       " 'add_cross_attention': False,\n",
       " 'tie_encoder_decoder': False,\n",
       " 'max_length': 20,\n",
       " 'min_length': 0,\n",
       " 'do_sample': False,\n",
       " 'early_stopping': False,\n",
       " 'num_beams': 1,\n",
       " 'num_beam_groups': 1,\n",
       " 'diversity_penalty': 0.0,\n",
       " 'temperature': 1.0,\n",
       " 'top_k': 50,\n",
       " 'top_p': 1.0,\n",
       " 'typical_p': 1.0,\n",
       " 'repetition_penalty': 1.0,\n",
       " 'length_penalty': 1.0,\n",
       " 'no_repeat_ngram_size': 0,\n",
       " 'encoder_no_repeat_ngram_size': 0,\n",
       " 'bad_words_ids': None,\n",
       " 'num_return_sequences': 1,\n",
       " 'output_scores': False,\n",
       " 'return_dict_in_generate': False,\n",
       " 'forced_bos_token_id': None,\n",
       " 'forced_eos_token_id': None,\n",
       " 'remove_invalid_values': False,\n",
       " 'exponential_decay_length_penalty': None,\n",
       " 'suppress_tokens': None,\n",
       " 'begin_suppress_tokens': None,\n",
       " 'architectures': ['DistilBertForMaskedLM'],\n",
       " 'finetuning_task': None,\n",
       " 'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3'},\n",
       " 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3},\n",
       " 'tokenizer_class': None,\n",
       " 'prefix': None,\n",
       " 'bos_token_id': None,\n",
       " 'pad_token_id': 0,\n",
       " 'eos_token_id': None,\n",
       " 'sep_token_id': None,\n",
       " 'decoder_start_token_id': None,\n",
       " 'task_specific_params': None,\n",
       " 'problem_type': None,\n",
       " '_name_or_path': 'distilbert-base-uncased',\n",
       " 'transformers_version': '4.41.2',\n",
       " 'model_type': 'distilbert',\n",
       " 'tie_weights_': True}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "# load transformer checkpoint from huggingface\n",
    "sentiment_model = (\n",
    "    TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    ")\n",
    "\n",
    "sentiment_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e8438ced-5ed0-412c-afe1-a17d156f5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  3076      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66956548 (255.42 MB)\n",
      "Trainable params: 66956548 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# freeze the first layer if needed\n",
    "sentiment_model.layers[0].trainable = True\n",
    "\n",
    "#add remove layers if needed.\n",
    "#sentiment_model.layers[append()/insert()/remove()]\n",
    "\n",
    "print(sentiment_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1996d-3bc6-4d12-804a-5270548458aa",
   "metadata": {},
   "source": [
    "### training the sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fbc6bc12-d9ad-4073-ba7e-bc568cb0b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0371 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.6707 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.8663 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.9228 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.8753 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0029 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8341 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8647 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8873 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9955 - val_loss: 1.0116 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9910 - val_loss: 1.0094 - val_sparse_categorical_accuracy: 0.8381\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.9696 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.9959 - val_sparse_categorical_accuracy: 0.8476\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.9684 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.6755 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.9840 - val_sparse_categorical_accuracy: 0.8286\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.6469 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0032 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9035 - val_sparse_categorical_accuracy: 0.8476\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 7.8762e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7754 - val_sparse_categorical_accuracy: 0.8190\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7712 - val_sparse_categorical_accuracy: 0.8095\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7725 - val_sparse_categorical_accuracy: 0.8286\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 6.4334e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8779 - val_sparse_categorical_accuracy: 0.8381\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7593 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7328 - val_sparse_categorical_accuracy: 0.8476\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 6.9938e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.8016 - val_sparse_categorical_accuracy: 0.8381\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.7477 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 34s 3s/step - loss: 4.9307e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7782 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.8258 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 5.1647e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.7710 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 35s 3s/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.9338 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9978 - val_loss: 1.0485 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 6.6055e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0417 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 5.9263e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9705 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 3.5917e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9148 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 3.2857e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9020 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 2.7444e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9055 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 4.3350e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9068 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 2.3058e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9166 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 2.2672e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9279 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 2.7245e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9625 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 1.9278e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9751 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.9501e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9809 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 35s 3s/step - loss: 1.7893e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9850 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 50s 4s/step - loss: 1.6080e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9888 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 1.5620e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9925 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 1.5035e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9963 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 1.5239e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0001 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 1.4731e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0047 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 1.3834e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0089 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 1.2978e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0126 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 1.2951e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0164 - val_sparse_categorical_accuracy: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x3227dfb60>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using features from pretrained model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "tokenizer_columns = db_tokenizer.model_input_names\n",
    "\n",
    "# convert to tf_tensors\n",
    "train_dataset = training_dataset.to_tf_dataset(columns = tokenizer_columns,\n",
    "                                               label_cols = [\"label\"], \n",
    "                                               shuffle=True,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "val_dataset = validation_dataset.to_tf_dataset(columns = tokenizer_columns,\n",
    "                                               label_cols = [\"label\"], \n",
    "                                               shuffle=True,\n",
    "                                               batch_size=batch_size)\n",
    "# compile the model\n",
    "sentiment_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5),\n",
    "                       loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                       metrics = tf.metrics.SparseCategoricalAccuracy())\n",
    "\n",
    "sentiment_model.fit(train_dataset,\n",
    "                   validation_data = val_dataset,\n",
    "                   epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f7a28-3c71-44c4-981b-33a48924e849",
   "metadata": {},
   "source": [
    "### Predicting sentiments with custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bf4360f0-beb2-4bcc-b4cf-b0a6a170ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "24e23541-7f8a-4959-ab40-28f7423f2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data for inference to predict sentiment\n",
    "# the 'label' is not needed but provided to compare true labels \n",
    "infer_data = {'id':[0,1],\n",
    "             'verse_text': ['and be glad in the summer morning when the kindred ride on their way', 'not happy with the lifes ways'],\n",
    "             'label':[1,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b3527825-64c4-4234-a164-552e5c3e7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    infer: Dataset({\n",
      "        features: ['id', 'verse_text', 'label'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da391baeb8b4fd6837db5e6c4765110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec={'input_ids': TensorSpec(shape=(None, 17), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 17), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "infer_dataset = Dataset.from_dict(infer_data)\n",
    "ds_dict = DatasetDict()\n",
    "\n",
    "ds_dict['infer'] = infer_dataset\n",
    "\n",
    "print(ds_dict)\n",
    "\n",
    "#encode dataset similar to training\n",
    "enc_dataset = ds_dict.map(tokenize, batched=True, batch_size=None)\n",
    "#convert to tensors\n",
    "infer_final_dataset = enc_dataset[\"infer\"].to_tf_dataset(columns = tokenizer_columns,\n",
    "                                               shuffle=True,\n",
    "                                               batch_size=batch_size)\n",
    "print(infer_final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b04b106f-0071-4c45-8ee3-35782d0bb130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 466ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.1005545,  6.787961 , -3.7919471, -2.8340926],\n",
       "       [ 1.868875 , -3.9656112, -0.5426691,  0.5009544]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sentiment_model.predict(infer_final_dataset)\n",
    "predictions.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "29e21972-d457-4286-9430-320c1a31a860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem:  and be glad in the summer morning when the kindred ride on their way \n",
      "\tPredicted Label:  positive \n",
      "\tTrue Label:  positive\n",
      "\n",
      "Poem:  not happy with the lifes ways \n",
      "\tPredicted Label:  negative \n",
      "\tTrue Label:  negative\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred_label_ids = np.argmax(predictions.logits, axis=1)\n",
    "\n",
    "for index, pred_label_id in enumerate(pred_label_ids):\n",
    "    print(\"\\nPoem: \", infer_data['verse_text'][index],\n",
    "         \"\\n\\tPredicted Label: \", labels.names[pred_label_ids[index]],\n",
    "         \"\\n\\tTrue Label: \", labels.names[infer_data['label'][index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d75fd6-6781-4816-8eeb-822ee1221a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35051d01-15da-438a-88a5-4932e0a686bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
